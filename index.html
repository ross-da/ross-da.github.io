<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charse
t=UTF-8">

  <title>David Ross</title>

  <meta name="author" content="David Ross">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/DR_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-
collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:s
eparate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:65%;vertical-align:middle">
              <p style="text-align:center">
                <name>David Ross</name>
                <br>
                 <a href="mailto:daross@gmail.com"
style="color:grey">daross at gmail dot com</a>
                <br>
                <br>
              </p>
              <p>I lead the Visual Dynamics research group, at <a href="https://research.google/">Google Research</a>. Our goal is to discover new ways to understand video, with an emphasis on objects, motion, and actions. The team's work includes the <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Tensorflow Object Detection API</a>, as well as models that help power <a href="https://ai.googleblog.com/2019/04/capturing-special-video-moments-with.html">personal video understanding in Google Photos</a> and <a href="https://cloud.google.com/video-intelligence/">Cloud Video Intelligence</a>. We publish research at top academic conferences including CVPR, and organize the <a href="https://research.google.com/ava/">AVA Challenge</a> to advance state-of-the-art spatiotemporal action recognition in video.
              </p>
              <p>
                Previously I led the YouTube Mix team that built the personalized algorithmic radio feature at the heart of <a href="https://music.youtube.com/">YouTube Music</a>.
              </p>
              <p>
                I obtained my Ph.D. in Machine Learning and Computer vision from the University of Toronto, Canada.
              </p>
              <p style="text-align:center">
                <a href="http://scholar.google.com/citations?user=RqOzJR0AAAAJ">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/daross_profile.jpg"><img style="width:100%;max-wi
dth:100%" alt="profile photo" src="images/daross_profile.jpg" class="hoverZoomL
ink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:s
eparate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Current Work</heading>
                <p>
                    Some of the latest open source releases from my team: <a href="https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html">TF Object Detection API for Tensorflow 2.x</a>, <a href="https://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html">TF3D for 3D Scene Understanding</a>, and the <a href="https://google.github.io/aistplusplus_dataset/">AIST++ Human Motion dataset</a>.
                    <br>
                    The results of the 3rd AVA Action Detection challenge are <a href="https://research.google.com/ava/challenge.html">now available</a>. This event was held at CVPR 2020, in partnership with the <a href="http://activity-net.org/challenges/2020/index.html">International Challenge on Activity Recognition (ActivityNet)</a> workshop.
                    <br>
                    My talk <a href="https://www.youtube.com/watch?v=IRYKpz6txeY&t=29703">Context & Attention for Detecting Objects and Actions in Video</a> at the CVPR'20 <a href="https://holistic-video-understanding.github.io/tutorials/cvpr2020.html">LSHVU Tutorial</a> is available on YouTube.
                    <br>
                    Our work on <a href="https://ai.googleblog.com/2019/04/capturing-special-video-moments-with.html">Capturing Special Video Moments with Google Photos</a> was just featured on the Google AI BLog.
                    <br>
                    I manage a research group in <a href="https://ai.google/research/teams/perception/">Perception</a>, part of <a href="https://ai.google/">Google AI Research</a>.
                </p>
              </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:s
eparate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                    <heading>Publications</heading>
                    <p>
                        A complete list of my publications and patents at <a href="http://scholar.google.com/citations?user=RqOzJR0AAAAJ">Google Scholar Citations</a>.
                    </p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>Distribution Aware Metrics for Conditional Natural Language Generation.</papertitle>
                  <br>
                  David M Chan, Yiming Ni, Austin Myers, Sudheendra Vijayanarasimhan, David A Ross, and John Canny
                  <br>
                  <em>arXiv preprint</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2209.07518">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>im2nerf: Image to Neural Radiance Field in the Wild.</papertitle>
                  <br>
                  Lu Mi, Abhijit Kundu, David Ross, Frank Dellaert, Noah Snavely, and Alireza Fathi
                  <br>
                  <em>arXiv preprint</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2209.04061">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>What’s in a Caption? Dataset-Specific Linguistic Diversity and Its Effect on Visual Description Models and Metrics.</papertitle>
                  <br>
                  David M. Chan, Austin Myers, Sudheendra Vijayanarasimhan, David A. Ross, Bryan Seybold, John F. Canny
                  <br>
                  <em><a href="https://sites.google.com/view/vdu-cvpr22">The 1st Workshop on Vision Datasets Understanding, at CVPR 2022</a></em>
                  <br>
                  <a href="https://arxiv.org/abs/2205.06253">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>Optical Mouse: 3D Mouse Pose From Single-View Video.</papertitle>
                  <br>
                  Bo Hu, Bryan Seybold, Shan Yang, David Ross, Avneesh Sud, Graham Ruby, and Yi Liu
                  <br>
                  <em><a href="https://www.cv4animals.com/paper">CV4Animals: Computer Vision for Animal Behavior Tracking and Modeling Workshop, at CVPR 2021</a></em>
                  <br>
                  <a href="https://arxiv.org/abs/2106.09251">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://google.github.io/aichoreographer/"><papertitle>AI Choreographer Music Conditioned 3D Dance Generation with AIST++</papertitle></a>
                  <br>
                  Ruilong Li, Shan Yang, David A. Ross, Angjoo Kanazawa
                  <br>
                  <em>ICCV</em>, 2021
                  <br>
                  <a href="https://arxiv.org/abs/2101.08779">arXiv</a> / <a href="https://google.github.io/aichoreographer/">project website, dataset</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>Learning Video Representations from Textual Web Supervision</papertitle>
                  <br>
                  Jonathan C. Stroud, David A. Ross, Chen Sun, Jia Deng, Rahul Sukthankar, Cordelia Schmid
                  <br>
                  <em>arXiv</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2007.14937">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/Chan_Active_Learning_for_Video_Description_With_Cluster-Regularized_Ensemble_Ranking_ACCV_2020_paper.pdf"><papertitle>Active Learning for Video Description With Cluster-Regularized Ensemble Ranking</papertitle></a>
                  <br>
                  David Chan, Sudheendra Vijayanarasimhan, David Ross, John Canny
                  <br>
                  <em>ACCV</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2007.13913">arXiv</a> / <a href="https://www.cs.toronto.edu/~dross/Chan_Active_Learning_for_Video_Description_With_Cluster-Regularized_Ensemble_Ranking_ACCV_2020_paper.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/Chan_Active_Learning_for_ACCV_2020_supplemental.pdf">supplementary</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>An LSTM Approach to Temporal 3D Object Detection in LiDAR Point Clouds</papertitle>
                  <br>
                  Rui Huang, Wanyue Zhang, Tom Funkhouser, Abhijit Kundu, David Ross, Caroline Pantofaru, Alireza Fathi
                  <br>
                  <em>ECCV</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2007.12392">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>Pillar-based Object Detection for Autonomous Driving</papertitle>
                  <br>
                  Yue Wang, Abhijit Kundu, Alireza Fathi, Caroline Pantofaru, David Ross, Justin Solomon, Tom Funkhouser
                  <br>
                  <em>ECCV</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2007.10323">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>Virtual Multi-view Fusion for 3D Semantic Segmentation</papertitle>
                  <br>
                  Abhijit Kundu, Xiaoqi (Michael) Yin, Alireza Fathi, Brew Barrington, David Ross, Tom Funkhouser, Caroline Pantofaru
                  <br>
                  <em>ECCV</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2007.13138">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://research.google.com/ava"><papertitle>The AVA-Kinetics Localized Human Actions Video Dataset</papertitle></a>
                  <br>
                  Ang Li, Meghana Thotakuri, David A. Ross, João Carreira, Alexander Vostrikov, Andrew Zisserman
                  <br>
                  <em>arXiv</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2005.00214">arXiv</a> / <a href="https://research.google.com/ava">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>DOPS: Learning to Detect 3D Objects and Predict their 3D Shapes</papertitle>
                  <br>
                  Mahyar Najibi, Guangda Lai, Abhijit Kundu, Zhichao Lu, Vivek Rathod, Thomas Funkhouser, Caroline Pantofaru, David Ross, Larry S. Davis, Alireza Fathi
                  <br>
                  <em>CVPR</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2004.01170">arXiv</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/nagrani20.pdf"><papertitle>Speech2Action: Cross-modal Supervision for Action Recognition</papertitle></a>
                  <br>
                  Arsha Nagrani, Chen Sun, David Ross, Rahul Sukthankar, Cordelia Schmid, Andrew Zisserman
                  <br>
                  <em>CVPR</em>, 2020
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/nagrani20.pdf">PDF</a> / <a href="https://arxiv.org/abs/2003.13594">arXiv</a> / <a href="https://www.robots.ox.ac.uk/~vgg/research/speech2action/">project page, data</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>D3D: Distilled 3D Networks for Video Action Recognition</papertitle>
                  <br>
                  Jonathan C. Stroud, David A. Ross, Chen Sun, Jia Deng, Rahul Sukthankar
                  <br>
                  <em>WACV</em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/1812.08249">arXiv</a> / <a href="https://github.com/princeton-vl/d3dhelper">code and pre-trained models</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <papertitle>Rethinking the Faster R-CNN Architecture for Temporal Action Localization</papertitle>
                  <br>
                  Yu-Wei Chao, Sudheendra Vijayanarasimhan, Bryan Seybold, David A Ross, Jia Deng, Rahul Sukthankar
                  <br>
                  <em>CVPR</em>, 2018
                  <br>
                  <a href="https://arxiv.org/abs/1804.07667">arXiv</a> / <a href="https://ai.googleblog.com/2019/04/capturing-special-video-moments-with.html">Google AI blog</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://research.google.com/ava"><papertitle>AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions</papertitle></a>
                  <br>
                  Chunhui Gu, Chen Sun, David A. Ross, Carl Vondrick, Caroline Pantofaru, Yeqing Li, Sudheendra Vijayanarasimhan, George Toderici, Susanna Ricco, Rahul Sukthankar, Cordelia Schmid, Jitendra Malik
                  <br>
                  <em>CVPR</em>, 2018
                  <br>
                  <a href="https://arxiv.org/abs/1705.08421">arXiv</a> / <a href="https://research.google.com/ava">project website</a> / <a href="https://ai.googleblog.com/2017/10/announcing-ava-finely-labeled-video.html">Google AI blog</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/MadaniGeorgRoss2013.pdf"><papertitle>On using nearly-independent feature families for high precision and confidence</papertitle></a>
                  <br>
                  Omid Madani, Manfred Georg, David Ross
                  <br>
                  <em>Machine Learning Journal</em>, 2013
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/MadaniGeorgRoss2013.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/WaltersRossLyon2012.pdf"><papertitle>The Intervalgram: An audio feature for large-scale melody recognition</papertitle></a>
                  <br>
                  Thomas C. Walters, David Ross, Richard F. Lyon
                  <br>
                  <em>9th International Symposium on Computer Music Modeling and Retrieval (CMMR 2012)</em>
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/WaltersRossLyon2012.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/MadaniGeorgRoss2012.pdf"><papertitle>On Using Nearly-Independent Feature Families for High Precision and Confidence</papertitle></a>
                  <br>
                  Omid Madani, Manfred Georg, David Ross
                  <br>
                  <em>4th Asian Conference on Machine Learning (ACML 2012)</em>
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/MadaniGeorgRoss2012.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/ChandrasekharSharifiRoss_ISMIR2011.pdf"><papertitle>Survey and Evaluation of Audio Fingerprinting Schemes for Mobile Query-by-Example Applications</papertitle></a>
                  <br>
                  Vijay Chandrasekhar, Matt Sharifi, David Ross
                  <br>
                  <em>12th International Society for Music Information Retrieval Conference (ISMIR 2011)</em>
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/ChandrasekharSharifiRoss_ISMIR2011.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/YagnikStrelowRossLin_ICCV2011.pdf"><papertitle>The Power of Comparative Reasoning</papertitle></a>
                  <br>
                  <a href="http://research.google.com/pubs/author36197.html">Jay Yagnik</a>, Dennis Strelow, David Ross, Ruei-Sung Lin
                  <br>
                  <em>ICCV</em>, 2011
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/YagnikStrelowRossLin_ICCV2011.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/ChandrasekharSarginRoss_ICASSP2011.pdf"><papertitle>Automatic Language Identification in Music Videos with Low Level Audio and Visual Features</papertitle></a>
                  <br>
                  Vijay Chandrasekhar, Mehmet Emre Sargin, and David Ross
                  <br>
                  <em>ICASSP</em>, 2011
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/ChandrasekharSarginRoss_ICASSP2011.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/LinRossYagnik_CVPR2010.pdf"><papertitle>SPEC Hashing: Similarity Preserving algorithm for Entropy-based Coding</papertitle></a>
                  <br>
                  Ruei-Sung Lin, David Ross, and <a href="http://research.google.com/pubs/author36197.html">Jay Yagnik</a>
                  <br>
                  <em>CVPR</em>, 2010
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/LinRossYagnik_CVPR2010.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/articulated/RossTarlowZemel_IJCV2010.pdf"><papertitle>Learning Articulated Structure and Motion</papertitle></a>
                  <br>
                  David Ross, <a href="http://www.cs.toronto.edu/~dtarlow/">Daniel Tarlow</a>, and <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>
                  <br>
                  <em>International Journal of Computer Vision, 88 (2)</em>, 2010
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/articulated/RossTarlowZemel_IJCV2010.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/articulated/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/phd/Ross_David_A_200811_PhD_thesis.pdf"><papertitle>Learning Probabilistic Models for Visual Motion</papertitle></a>
                  <br>
                  David Ross
                  <br>
                  <em>Ph.D. Thesis, University of Toronto, Canada</em>, 2008
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/phd/Ross_David_A_200811_PhD_thesis.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/phd/">videos</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/articulated/RossTarlowZemel_ECCV2008.pdf"><papertitle>Unsupervised learning of skeletons from motion</papertitle></a>
                  <br>
                  David Ross, <a href="http://www.cs.toronto.edu/~dtarlow/">Daniel Tarlow</a>, and <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>
                  <br>
                  <em>10th European Conference on Computer Vision (ECCV 2008)</em>, 2008
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/articulated/RossTarlowZemel_ECCV2008.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/articulated/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/articulated/MeedsRossZemelRoweis_CVPR2008.pdf"><papertitle>Learning stick-figure models using nonparametric Bayesian priors over trees</papertitle></a>
                  <br>
                  <a href="https://scholar.google.nl/citations?hl=en&pli=1&user=oxrYi1cAAAAJ">Edward Meeds</a>, David Ross, <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>, and <a href="http://www.cs.toronto.edu/~roweis/">Sam Roweis</a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition</em>, 2008
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/articulated/MeedsRossZemelRoweis_CVPR2008.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/articulated/RossTarlowZemel_WDV2007.pdf"><papertitle>Learning Articulated Skeletons From Motion</papertitle></a>
                  <br>
                  David Ross, <a href="http://www.cs.toronto.edu/~dtarlow/">Daniel Tarlow</a>, and <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>
                  <br>
                  <em><a href="http://vision.jhu.edu/iccv2007-wdv/">Workshop on Dynamical Vision at ICCV</a></em>, 2007
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/articulated/RossTarlowZemel_WDV2007.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/articulated/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf"><papertitle>Incremental Learning for Robust Visual Tracking</papertitle></a>
                  <br>
                  David Ross, <a href="http://vision.ucsd.edu/~jwlim/">Jongwoo Lim</a>, <a href="http://www.ifp.uiuc.edu/~rlin1/">Ruei-Sung Lin</a>, <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en/">Ming-Hsuan Yang</a>
                  <br>
                  <em>In the <a href="http://www.springerlink.com/">International Journal of Computer Vision, Special Issue: Learning for Vision</a></em>, 2008
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="http://www.journalofvision.org/7/8/15/Cohen-2007-jov-7-8-15.pdf"><papertitle>Inducing Features from Visual Noise</papertitle></a>
                  <br>
                  <a href="http://people.umass.edu/alc/">Andrew Cohen</a>, <a href="http://mypage.iu.edu/~maplab/home1.html">Richard Shiffrin</a>, Jason Gold, David Ross, and Michael Ross
                  <br>
                  <em><a href="http://www.journalofvision.org/7/8/15/">Journal of Vision, 7(8):15</a></em>, 2007
                  <br>
                  <a href="http://www.journalofvision.org/7/8/15/Cohen-2007-jov-7-8-15.pdf">PDF</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/mcvq/RossZemel_JMLR06.pdf"><papertitle>Learning Parts-Based Representations of Data</papertitle></a>
                  <br>
                  David Ross and <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>
                  <br>
                  <em><a href="http://jmlr.csail.mit.edu/papers/v7/">Journal of Machine Learning Research, 7(Nov):2369-2397</a></em>, 2006
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/mcvq/RossZemel_JMLR06.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/mcvq/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/cdf_icml06/RossOsinderoZemel_ICML06.pdf"><papertitle>Combining Discriminative Features to Infer Complex Trajectories</papertitle></a>
                  <br>
                  David Ross, <a href="http://www.cs.toronto.edu/~osindero/">Simon Osindero</a>, and <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>
                  <br>
                  <em>In Proceedings of the Twenty-Third International Conference on Machine Learning</em>, 2006
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/cdf_icml06/RossOsinderoZemel_ICML06.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/cdf_icml06/RossOsinderoZemel_ICML06.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/cdf_icml06/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/ivt/LimRossLinYang_nips04.pdf"><papertitle>Incremental Learning for Visual Tracking</papertitle></a>
                  <br>
                  <a href="http://vision.ucsd.edu/~jwlim/">Jongwoo Lim</a>, David Ross, <a href="http://www.ifp.uiuc.edu/~rlin1/">Ruei-Sung Lin</a>, <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en/">Ming-Hsuan Yang</a>
                  <br>
                  <em>In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17, MIT Press</em>, 2005
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/ivt/LimRossLinYang_nips04.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/LimRossLinYang_nips04.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/ivt/LinRossLimYang_nips04.pdf"><papertitle>Adaptive Discriminative Generative Model and Its Applications</papertitle></a>
                  <br>
                  <a href="http://www.ifp.uiuc.edu/~rlin1/">Ruei-Sung Lin</a>, David Ross, <a href="http://vision.ucsd.edu/~jwlim/">Jongwoo Lim</a>, <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en/">Ming-Hsuan Yang</a>
                  <br>
                  <em>In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17, MIT Press</em>, 2005
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/ivt/LinRossLimYang_nips04.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/LinRossLimYang_nips04.pdf">PDF</a> / <a href="http://www.ifp.uiuc.edu/~rlin1/adgm.html">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/ivt/RossLimYang_IVT.pdf"><papertitle>Adaptive Probabilistic Visual Tracking with Incremental Subspace Update</papertitle></a>
                  <br>
                  David Ross, <a href="http://vision.ucsd.edu/~jwlim/">Jongwoo Lim</a>, <a href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en/">Ming-Hsuan Yang</a>
                  <br>
                  <em>In T. Pajdla and J. Matas, editors, Proc. Eighth European Conference on Computer Vision (ECCV 2004)</em>, 2004
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/ivt/RossLimYang_IVT.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/RossLimYang_IVT.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/ivt/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/mcvq/RossZemel_MCVQ.pdf"><papertitle>Multiple Cause Vector Quantization</papertitle></a>
                  <br>
                  David Ross and <a href="http://www.cs.toronto.edu/~zemel/">Richard Zemel</a>
                  <br>
                  <em>In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15, MIT Press</em>, 2003
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/mcvq/RossZemel_MCVQ.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/mcvq/RossZemel_MCVQ.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/mcvq/">project website</a>
                  <p></p>
                </td>
            </tr>
            <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                  <a href="https://www.cs.toronto.edu/~dross/mcvq/Ross_msc_thesis.pdf"><papertitle>Learning Parts-Based Representations of Data (thesis version)</papertitle></a>
                  <br>
                  David Ross
                  <br>
                  <em>University of Toronto, M.Sc. Thesis</em>, 2003
                  <br>
                  <a href="https://www.cs.toronto.edu/~dross/mcvq/Ross_msc_thesis.ps.gz">PS.GZ</a> / <a href="https://www.cs.toronto.edu/~dross/mcvq/Ross_msc_thesis.pdf">PDF</a> / <a href="https://www.cs.toronto.edu/~dross/mcvq/">project website</a>
                  <p></p>
                </td>
            </tr>
             <tr>
                <td width="100%" valign="middle" style="padding:20px;">
                    Bibtex entries for all of the above are available <a href="https://www.cs.toronto.edu/~dross/Ross.bib">here</a>.
                </td>
            </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Code</heading>
            </td>
          </tr>
          <tr>
            <td width="100%" valign="middle">
                D3D: Distilled 3D Networks TensorFlow code and pre-trained model checkpoints can be found <a href="https://github.com/princeton-vl/d3dhelper">here</a>.
                <br><br>
                AVA Atomic Visual Actions evaluation code can be found in the <a href="https://github.com/activitynet/ActivityNet/tree/master/Evaluation">ActivityNet Github repo</a>. Find the data <a href="http://research.google.com/ava/">here</a>.
                <br><br>
                The source code for most of my older research projects is <a href="https://www.cs.toronto.edu/~dross/code/">available for download here</a>. Included are <a href="https://www.cs.toronto.edu/~dross/code/#matlab">Matlab implementations</a> of a number of machine learning & computer vision algorithms, but there are also a few <a href="https://www.cs.toronto.edu/~dross/code/#hacks">other hacks</a>.
                <br><br>
                Parallel Computing: Here is some code I've written/modified, as well as some getting-started tips for <a href="https://www.cs.toronto.edu/~dross/code/parallel.shtml">parallel computing using Matlab</a>.
                <br><br>
                The code for the "Combining Discriminative Features" learning/tracking algorithm is available. <a href="https://www.cs.toronto.edu/~dross/code/cdf_2007-07-13.zip">cdf_2007-07-13.zip</a>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Other Stuff</heading>
            </td>
          </tr>
          <tr>
            <td width="100%" valign="middle">
                <a href="https://www.instagram.com/modernschnauz/">Photos of my dog.</a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:s
eparate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 <a href="https://jonbarron.info/">This</a> guy is good at websi
te design. <br> Last Updated: October 2022.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
